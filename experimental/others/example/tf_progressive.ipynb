{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43adf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "from time import perf_counter\n",
    "from tensorflow import keras\n",
    "#import keras_core as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9fb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Setting\n",
    "device_index = -1\n",
    "MIXED_PRECISION_FLAG = True\n",
    "JIT_COMPILE_FLAG = True\n",
    "\n",
    "# Data && Model Setting\n",
    "## Data Resize Shape\n",
    "resizing = 32 # 16, '32'\n",
    "## Dataloader Setting\n",
    "batch_size = 500\n",
    "validation_batch_size = 1000\n",
    "drop_remainder = False\n",
    "num_parallel_calls = tf.data.AUTOTUNE\n",
    "## Model Setting\n",
    "n = 3\n",
    "rate = 0.2 # 0.1, '0.2'\n",
    "classes = 100\n",
    "## RandAugment\n",
    "augmentations_per_image = 2\n",
    "magnitude = 0.2 # 0.1, '0.2'\n",
    "rand_augment = False # rand_augment failed if using mixed_precision\n",
    "\n",
    "# Training Setting\n",
    "epochs = 160 # 160\n",
    "## loss function\n",
    "learning_rate = 1e-1 #* batch_size / 128\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4 # 1e-4\n",
    "## lr scheduler\n",
    "milestones = [80, 120] # [80, 120]\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732520d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_schedule = {\n",
    "    'milestones': [40, 80, 100, 120, 140],\n",
    "    'counter': 0,\n",
    "    'len': 2,\n",
    "    'size': [16, 32],\n",
    "    'magnitude': [5, 10],\n",
    "    'p': [0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d291fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(f'Numbers of Physical Devices: {len(physical_devices)}')\n",
    "tf.config.set_visible_devices(physical_devices[device_index], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[device_index], True)\n",
    "print(f'Using device: {physical_devices[device_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d768bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only TPUs support 'mixed_bfloat16'\n",
    "# if using NVIDIA GPUs, choose 'mixed_float16'\n",
    "if MIXED_PRECISION_FLAG:\n",
    "    policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "    keras.mixed_precision.set_global_policy(policy)\n",
    "    print(f'Policy: {policy.name}')\n",
    "    print(f'Compute dtype: {policy.compute_dtype}')\n",
    "    print(f'Variable dtype: {policy.variable_dtype}')\n",
    "    #keras.mixed_precision.set_dtype_policy('mixed_float16')\n",
    "    #print(f'{keras.mixed_precision.dtype_policy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100(\n",
    "    batch_size: int = 128,\n",
    "    validation_batch_size: int = 128,\n",
    "    resizing: int = 32,\n",
    "    augmentations_per_image: int = 2,\n",
    "    magnitude: float = 0.2,\n",
    "    drop_remainder: bool = False,\n",
    "    num_parallel_calls: int = tf.data.AUTOTUNE,\n",
    "    rand_augment: bool = False\n",
    "):\n",
    "    '''\n",
    "    # for cifar-10\n",
    "    ## mean = [0.491, 0.482, 0.447]\n",
    "    ## variance = [0.061, 0.059, 0.068]\n",
    "    # for cifar-100\n",
    "    ## mean = [0.507, 0.487, 0.441]\n",
    "    ## variance = [0.072, 0.066, 0.076]\n",
    "    '''\n",
    "    mean = [0.507, 0.487, 0.441]\n",
    "    variance = [0.072, 0.066, 0.076]\n",
    "    \n",
    "    def map_train_before_cache(image, label, resizing):\n",
    "        transform = keras.Sequential([\n",
    "            keras.layers.Resizing(height=resizing, width=resizing)\n",
    "        ])\n",
    "        return transform(image), label\n",
    "    \n",
    "    def map_train_after_cache(image, label, rand_augment):\n",
    "        transform = keras.Sequential()\n",
    "        if rand_augment:\n",
    "            transform.add(\n",
    "                keras_cv.layers.RandAugment(\n",
    "                    value_range=(0, 255),\n",
    "                    augmentations_per_image=augmentations_per_image,\n",
    "                    magnitude=magnitude\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            transform.add(\n",
    "                keras.layers.RandomTranslation(\n",
    "                    height_factor=0.125,\n",
    "                    width_factor=0.125,\n",
    "                    fill_mode='constant'\n",
    "                )\n",
    "            )\n",
    "        transform.add(keras.layers.RandomFlip('horizontal'))\n",
    "        transform.add(keras.layers.Rescaling(1/255))\n",
    "        transform.add(keras.layers.Normalization(mean=mean, variance=variance))\n",
    "        return transform(image), label\n",
    "    \n",
    "    def map_test(image, label, resizing):\n",
    "        transform = keras.Sequential([\n",
    "            keras.layers.Resizing(height=resizing, width=resizing),\n",
    "            keras.layers.Rescaling(1/255),\n",
    "            keras.layers.Normalization(mean=mean, variance=variance)\n",
    "        ])\n",
    "        return transform(image), label\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "    dataloader = {\n",
    "        'train': (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                  .map(lambda x, y: (map_train_before_cache(x, y, resizing)),\n",
    "                       num_parallel_calls=num_parallel_calls)\n",
    "                  .cache()\n",
    "                  .shuffle(buffer_size=len(x_train))\n",
    "                  .map(lambda x, y: (map_train_after_cache(x, y, rand_augment)),\n",
    "                       num_parallel_calls=num_parallel_calls)\n",
    "                  .batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "                  .prefetch(buffer_size=tf.data.AUTOTUNE)),\n",
    "        'test': (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "                 .map(lambda x, y: (map_test(x, y, resizing)),\n",
    "                      num_parallel_calls=num_parallel_calls)\n",
    "                 .cache()\n",
    "                 .batch(batch_size=validation_batch_size)\n",
    "                 .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "    }\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cifar_resnet(\n",
    "    resizing: int = 32,\n",
    "    n: int = 3,\n",
    "    rate: float = 0.2,\n",
    "    classes: int = 100\n",
    ") -> keras.Model:\n",
    "    \n",
    "    def basic_block(x: keras.Input, filters: int, conv_shortcut: bool = False):\n",
    "        if conv_shortcut:\n",
    "            shortcut = keras.layers.Conv2D(\n",
    "                filters, 1, strides=2, use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "            shortcut = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(shortcut)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters, 3, padding='same', use_bias=False,\n",
    "            kernel_initializer='he_normal',\n",
    "            #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Add()([shortcut, x])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def basic_stack(x: keras.Input, filters: int, conv_shortcut: bool = False):\n",
    "        for i in range(n):\n",
    "            if i == 0 and conv_shortcut == True:\n",
    "                filters *= 2\n",
    "                x = basic_block(x, filters, conv_shortcut)\n",
    "            else:\n",
    "                x = basic_block(x, filters)\n",
    "        return x, filters\n",
    "    \n",
    "    inputs = keras.Input(shape=(resizing, resizing, 3))\n",
    "    filters = 16\n",
    "    x = keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', use_bias=False,\n",
    "        kernel_initializer='he_normal',\n",
    "        #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "    )(inputs)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x, filters = basic_stack(x, filters)\n",
    "    x, filters = basic_stack(x, filters, True)\n",
    "    x, filters = basic_stack(x, filters, True)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(rate)(x)\n",
    "    outputs = keras.layers.Dense(classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_old_cifar_resnet(\n",
    "    resizing: int = 32,\n",
    "    filters: int = 64,\n",
    "    repeat: list = [2, 2, 2, 2], # [2, 2, 2, 2] for 18-layer, [3, 4, 6, 3] for 34-layer\n",
    "    rate: float = 0.2,\n",
    "    classes: int = 100\n",
    ") -> keras.Model:\n",
    "    \n",
    "    def basic_block(x: keras.Input, filters: int, conv_shortcut: bool = False):\n",
    "        if conv_shortcut:\n",
    "            shortcut = keras.layers.Conv2D(\n",
    "                filters, 1, strides=2, use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "            shortcut = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(shortcut)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters, 3, padding='same', use_bias=False,\n",
    "            kernel_initializer='he_normal',\n",
    "            #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Add()([shortcut, x])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def basic_stack(x: keras.Input, filters: int, n: int, conv_shortcut: bool = False):\n",
    "        for i in range(n):\n",
    "            if i == 0 and conv_shortcut == True:\n",
    "                filters *= 2\n",
    "                x = basic_block(x, filters, conv_shortcut)\n",
    "            else:\n",
    "                x = basic_block(x, filters)\n",
    "        return x, filters\n",
    "    \n",
    "    inputs = keras.Input(shape=(resizing, resizing, 3))\n",
    "    filters = 16\n",
    "    x = keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', use_bias=False,\n",
    "        kernel_initializer='he_normal',\n",
    "        #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "    )(inputs)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    for i, n in enumerate(repeat):\n",
    "        if i == 0:\n",
    "            x, filters = basic_stack(x, filters, n)\n",
    "        else:\n",
    "            x, filters = basic_stack(x, filters, n, True)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(rate)(x)\n",
    "    outputs = keras.layers.Dense(classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = load_cifar100(\n",
    "    batch_size=batch_size,\n",
    "    validation_batch_size=validation_batch_size,\n",
    "    resizing=resizing,\n",
    "    augmentations_per_image=augmentations_per_image,\n",
    "    magnitude=magnitude,\n",
    "    drop_remainder=drop_remainder,\n",
    "    num_parallel_calls=num_parallel_calls,\n",
    "    rand_augment=rand_augment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56163eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = build_cifar_resnet(resizing=resizing, n=n, rate=rate, classes=classes)\n",
    "model = build_old_cifar_resnet(resizing=resizing, rate=rate, classes=classes)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a78fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr, milestones, gamma: float = 0.1):\n",
    "    if epoch in milestones:\n",
    "        lr *= gamma\n",
    "    return lr\n",
    "\n",
    "class TimeCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.history = []\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.time_epoch_begin = perf_counter()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history.append(perf_counter() - self.time_epoch_begin)\n",
    "\n",
    "lr_scheduler_callback = keras.callbacks.LearningRateScheduler(\n",
    "    lambda x, y: lr_schedule(x, y, milestones=milestones, gamma=gamma)\n",
    ")\n",
    "time_callback = TimeCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    ),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=JIT_COMPILE_FLAG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449564bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training time warm-up\n",
    "'''\n",
    "class StopCallBack(keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.model.stop_training = True\n",
    "stop_call = StopCallBack()\n",
    "model.fit(dataloader['train'], verbose=2, callbacks=[stop_call])\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd619f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = model.fit(\n",
    "    dataloader['train'],\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    callbacks=[lr_scheduler_callback, time_callback],\n",
    "    validation_data=dataloader['test']\n",
    ")\n",
    "logs.history['t'] = time_callback.history\n",
    "#logs.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1\n",
    "print('----')\n",
    "print('PRINT RESULTS')\n",
    "print(f'batch_size: {batch_size}')\n",
    "print(f'MIXED_PRECISION: {MIXED_PRECISION_FLAG}')\n",
    "print(f'JIT_COMPILE: {JIT_COMPILE_FLAG}')\n",
    "print(f'time: {logs.history[\"t\"][index]}')\n",
    "print(f'learning_rate: {logs.history[\"lr\"][index]}')\n",
    "print(f'loss: {logs.history[\"loss\"][index]}')\n",
    "print(f'acc: {logs.history[\"accuracy\"][index]}')\n",
    "print(f'val_loss: {logs.history[\"val_loss\"][index]}')\n",
    "print(f'val_acc: {logs.history[\"val_accuracy\"][index]}')\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11354a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "----\n",
    "PRINT RESULTS\n",
    "batch_size: 2048\n",
    "MIXED_PRECISION: True\n",
    "JIT_COMPILE: True\n",
    "time: 7.176191415870562\n",
    "learning_rate: 0.0009999999310821295\n",
    "loss: 0.9402134418487549\n",
    "acc: 0.7233999967575073\n",
    "val_loss: 2.5140624046325684\n",
    "val_acc: 0.44749999046325684\n",
    "----\n",
    "----\n",
    "PRINT RESULTS\n",
    "batch_size: 512\n",
    "MIXED_PRECISION: True\n",
    "JIT_COMPILE: True\n",
    "time: 7.181444549933076\n",
    "learning_rate: 0.0009999999310821295\n",
    "loss: 0.45324844121932983\n",
    "acc: 0.8585600256919861\n",
    "val_loss: 2.8365235328674316\n",
    "val_acc: 0.4674000144004822\n",
    "----\n",
    "----\n",
    "PRINT RESULTS\n",
    "batch_size: 128\n",
    "MIXED_PRECISION: True\n",
    "JIT_COMPILE: True\n",
    "time: 8.163974148919806\n",
    "learning_rate: 0.0009999999310821295\n",
    "loss: 0.4783342182636261\n",
    "acc: 0.8499000072479248\n",
    "val_loss: 2.6634764671325684\n",
    "val_acc: 0.5026000142097473\n",
    "----\n",
    "----\n",
    "PRINT RESULTS\n",
    "batch_size: 32\n",
    "MIXED_PRECISION: True\n",
    "JIT_COMPILE: True\n",
    "time: 18.20342784305103\n",
    "learning_rate: 0.0009999999310821295\n",
    "loss: 0.9204937219619751\n",
    "acc: 0.7246999740600586\n",
    "val_loss: 2.087597608566284\n",
    "val_acc: 0.5317999720573425\n",
    "----\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
