{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43adf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import perf_counter\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Too simple! Sometimes naive!'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-b', '--begin',\n",
    "    type=int,\n",
    "    default=512,\n",
    "    help='begin batch size'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-e', '--end',\n",
    "    type=int,\n",
    "    default=512,\n",
    "    help='end batch size'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-g', '--gap',\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help='batch size gap (step size)'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-s', '--size',\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help='image size (n x n)'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-m', '--mixed',\n",
    "    type=bool,\n",
    "    default=False,\n",
    "    help='mixed precision'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-j', '--jit',\n",
    "    type=bool,\n",
    "    default=False,\n",
    "    help='jit compile'\n",
    ")\n",
    "# parser.parse_args() is used in .py files\n",
    "# parser.parse_args('') is used in .ipynb files\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9fb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Setting\n",
    "device_index = -1\n",
    "MIXED_PRECISION_FLAG = args.mixed\n",
    "JIT_COMPILE_FLAG = args.jit\n",
    "\n",
    "# Data && Model Setting\n",
    "## Data Resize Shape\n",
    "resizing = args.size # 16, '32'\n",
    "## Dataloader Setting\n",
    "batch_size = 512\n",
    "validation_batch_size = 1000\n",
    "drop_remainder = False\n",
    "num_parallel_calls = tf.data.AUTOTUNE\n",
    "## Model Setting\n",
    "rate = 0.2 # 0.1, '0.2'\n",
    "classes = 100\n",
    "## RandAugment\n",
    "augmentations_per_image = 2\n",
    "magnitude = 0.2 # 0.1, '0.2'\n",
    "rand_augment = False # rand_augment failed if using mixed_precision\n",
    "\n",
    "# Training Setting\n",
    "epochs = 1 # 160\n",
    "## loss function\n",
    "learning_rate = 1e-1 #* batch_size / 128\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4 # 1e-4\n",
    "## lr scheduler\n",
    "milestones = [80, 120] # [80, 120]\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d291fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(f'Numbers of Physical Devices: {len(physical_devices)}')\n",
    "tf.config.set_visible_devices(physical_devices[device_index], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[device_index], True)\n",
    "print(f'Using device: {physical_devices[device_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d768bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only TPUs support 'mixed_bfloat16'\n",
    "# if using NVIDIA GPUs, choose 'mixed_float16'\n",
    "if MIXED_PRECISION_FLAG:\n",
    "    policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "    keras.mixed_precision.set_global_policy(policy)\n",
    "    print(f'Policy: {policy.name}')\n",
    "    print(f'Compute dtype: {policy.compute_dtype}')\n",
    "    print(f'Variable dtype: {policy.variable_dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100(\n",
    "    batch_size: int = 128,\n",
    "    validation_batch_size: int = 128,\n",
    "    resizing: int = 32,\n",
    "    augmentations_per_image: int = 2,\n",
    "    magnitude: float = 0.2,\n",
    "    drop_remainder: bool = False,\n",
    "    num_parallel_calls: int = tf.data.AUTOTUNE,\n",
    "    rand_augment: bool = False\n",
    "):\n",
    "    '''\n",
    "    # for cifar-10\n",
    "    ## mean = [0.491, 0.482, 0.447]\n",
    "    ## variance = [0.061, 0.059, 0.068]\n",
    "    # for cifar-100\n",
    "    ## mean = [0.507, 0.487, 0.441]\n",
    "    ## variance = [0.072, 0.066, 0.076]\n",
    "    '''\n",
    "    mean = [0.507, 0.487, 0.441]\n",
    "    variance = [0.072, 0.066, 0.076]\n",
    "    \n",
    "    def map_train_before_cache(image, label, resizing):\n",
    "        transform = keras.Sequential([\n",
    "            keras.layers.Resizing(height=resizing, width=resizing)\n",
    "        ])\n",
    "        return transform(image), label\n",
    "    \n",
    "    def map_train_after_cache(image, label, rand_augment):\n",
    "        transform = keras.Sequential()\n",
    "        if rand_augment:\n",
    "            transform.add(\n",
    "                keras_cv.layers.RandAugment(\n",
    "                    value_range=(0, 255),\n",
    "                    augmentations_per_image=augmentations_per_image,\n",
    "                    magnitude=magnitude\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            transform.add(\n",
    "                keras.layers.RandomTranslation(\n",
    "                    height_factor=0.125,\n",
    "                    width_factor=0.125,\n",
    "                    fill_mode='constant'\n",
    "                )\n",
    "            )\n",
    "        transform.add(keras.layers.RandomFlip('horizontal'))\n",
    "        transform.add(keras.layers.Rescaling(1/255))\n",
    "        transform.add(keras.layers.Normalization(mean=mean, variance=variance))\n",
    "        return transform(image), label\n",
    "    \n",
    "    def map_test(image, label, resizing):\n",
    "        transform = keras.Sequential([\n",
    "            keras.layers.Resizing(height=resizing, width=resizing),\n",
    "            keras.layers.Rescaling(1/255),\n",
    "            keras.layers.Normalization(mean=mean, variance=variance)\n",
    "        ])\n",
    "        return transform(image), label\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "    dataloader = {\n",
    "        'train': (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                  .map(lambda x, y: (map_train_before_cache(x, y, resizing)),\n",
    "                       num_parallel_calls=num_parallel_calls)\n",
    "                  .cache()\n",
    "                  .shuffle(buffer_size=len(x_train))\n",
    "                  .map(lambda x, y: (map_train_after_cache(x, y, rand_augment)),\n",
    "                       num_parallel_calls=num_parallel_calls)\n",
    "                  .batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "                  .prefetch(buffer_size=tf.data.AUTOTUNE)),\n",
    "        'test': (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "                 .map(lambda x, y: (map_test(x, y, resizing)),\n",
    "                      num_parallel_calls=num_parallel_calls)\n",
    "                 .cache()\n",
    "                 .batch(batch_size=validation_batch_size)\n",
    "                 .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "    }\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cifar_resnet(\n",
    "    resizing: int = 32,\n",
    "    n: int = 3,\n",
    "    rate: float = 0.2,\n",
    "    classes: int = 100\n",
    ") -> keras.Model:\n",
    "    \n",
    "    def basic_block(x: keras.Input, filters: int, conv_shortcut: bool = False):\n",
    "        if conv_shortcut:\n",
    "            shortcut = keras.layers.Conv2D(\n",
    "                filters, 1, strides=2, use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "            shortcut = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(shortcut)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters, 3, padding='same', use_bias=False,\n",
    "            kernel_initializer='he_normal',\n",
    "            #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Add()([shortcut, x])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def basic_stack(x: keras.Input, filters: int, conv_shortcut: bool = False):\n",
    "        for i in range(n):\n",
    "            if i == 0 and conv_shortcut == True:\n",
    "                filters *= 2\n",
    "                x = basic_block(x, filters, conv_shortcut)\n",
    "            else:\n",
    "                x = basic_block(x, filters)\n",
    "        return x, filters\n",
    "    \n",
    "    inputs = keras.Input(shape=(resizing, resizing, 3))\n",
    "    filters = 16\n",
    "    x = keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', use_bias=False,\n",
    "        kernel_initializer='he_normal',\n",
    "        #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "    )(inputs)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x, filters = basic_stack(x, filters)\n",
    "    x, filters = basic_stack(x, filters, True)\n",
    "    x, filters = basic_stack(x, filters, True)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(rate)(x)\n",
    "    outputs = keras.layers.Dense(classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_old_cifar_resnet(\n",
    "    resizing: int = 32,\n",
    "    filters: int = 64,\n",
    "    repeat: list = [2, 2, 2, 2], # [2, 2, 2, 2] for 18-layer, [3, 4, 6, 3] for 34-layer\n",
    "    rate: float = 0.2,\n",
    "    classes: int = 100\n",
    ") -> keras.Model:\n",
    "    \n",
    "    def basic_block(x: keras.Input, filters: int, conv_shortcut: bool = False):\n",
    "        if conv_shortcut:\n",
    "            shortcut = keras.layers.Conv2D(\n",
    "                filters, 1, strides=2, use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "            shortcut = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(shortcut)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters, 3, padding='same', use_bias=False,\n",
    "                kernel_initializer='he_normal',\n",
    "                #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "            )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters, 3, padding='same', use_bias=False,\n",
    "            kernel_initializer='he_normal',\n",
    "            #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "        x = keras.layers.Add()([shortcut, x])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def basic_stack(x: keras.Input, filters: int, n: int, conv_shortcut: bool = False):\n",
    "        for i in range(n):\n",
    "            if i == 0 and conv_shortcut == True:\n",
    "                filters *= 2\n",
    "                x = basic_block(x, filters, conv_shortcut)\n",
    "            else:\n",
    "                x = basic_block(x, filters)\n",
    "        return x, filters\n",
    "    \n",
    "    inputs = keras.Input(shape=(resizing, resizing, 3))\n",
    "    x = keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', use_bias=False,\n",
    "        kernel_initializer='he_normal',\n",
    "        #kernel_regularizer=keras.regularizers.L2(1e-4)\n",
    "    )(inputs)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5)(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    for i, n in enumerate(repeat):\n",
    "        if i == 0:\n",
    "            x, filters = basic_stack(x, filters, n)\n",
    "        else:\n",
    "            x, filters = basic_stack(x, filters, n, True)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(rate)(x)\n",
    "    outputs = keras.layers.Dense(classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56163eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = build_cifar_resnet(resizing=resizing, n=3, rate=rate, classes=classes)\n",
    "model = build_old_cifar_resnet(\n",
    "    resizing=resizing, filters=64, repeat=[2, 2, 2, 2], rate=rate, classes=classes\n",
    ")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a78fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr, milestones, gamma: float = 0.2):\n",
    "    if epoch in milestones:\n",
    "        lr *= gamma\n",
    "    return lr\n",
    "\n",
    "class TimeCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.history = []\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.time_epoch_begin = perf_counter()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history.append(perf_counter() - self.time_epoch_begin)\n",
    "\n",
    "lr_scheduler_callback = keras.callbacks.LearningRateScheduler(\n",
    "    lambda x, y: lr_schedule(x, y, milestones=milestones, gamma=gamma)\n",
    ")\n",
    "time_callback = TimeCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopCallBack(keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.model.stop_training = True\n",
    "\n",
    "stop_call = StopCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    ),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=JIT_COMPILE_FLAG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd619f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_record = []\n",
    "for i in range(args.begin, args.end + 1, args.gap):\n",
    "    dataloader = load_cifar100(\n",
    "        batch_size=i,\n",
    "        validation_batch_size=validation_batch_size,\n",
    "        resizing=resizing,\n",
    "        augmentations_per_image=augmentations_per_image,\n",
    "        magnitude=magnitude,\n",
    "        drop_remainder=drop_remainder,\n",
    "        num_parallel_calls=num_parallel_calls,\n",
    "        rand_augment=rand_augment\n",
    "    )\n",
    "    # warming\n",
    "    model.fit(dataloader['train'], verbose=2, callbacks=[stop_call])\n",
    "    # testing\n",
    "    logs = model.fit(\n",
    "        dataloader['train'],\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        callbacks=[time_callback]\n",
    "    )\n",
    "    # record traing time\n",
    "    time_record.append(time_callback.history[0])\n",
    "    print('----')\n",
    "    print(f'batch_size: {i}')\n",
    "    print(f'MIXED_PRECISION: {MIXED_PRECISION_FLAG}, JIT_COMPILE: {JIT_COMPILE_FLAG}')\n",
    "    print(f'time: {time_callback.history[0]}')\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11354a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_record = np.array(time_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(f'time_cResNet{6*n+2}_s{resizing}_b{args.begin}_e{args.end}_g{args.gap}.npy', time_record)\n",
    "np.save(f'time_cResNetOld18_s{resizing}_b{args.begin}_e{args.end}_g{args.gap}.npy', time_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0199183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
