{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c9b9a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'c24': [],\n",
    "    'c32': [],\n",
    "    'cx24': [],\n",
    "    'cx32': [],\n",
    "    'ia160': [],\n",
    "    'ia224': [],\n",
    "    'ia288': [],\n",
    "    'iax160': [],\n",
    "    'iax224': [],\n",
    "    'iax288': [],\n",
    "}\n",
    "verbose_label = {\n",
    "    'c24': 'cifar100_resnet18_r24_10_601_10',\n",
    "    'c32': 'cifar100_resnet18_r32_10_571_10',\n",
    "    'cx24': 'cifar100_resnet18_r24_20_2561_20_xla',\n",
    "    'cx32': 'cifar100_resnet18_r32_20_1461_20_xla',\n",
    "    'ia160': 'imagenet_resnet18_r160_10_341_10_amp',\n",
    "    'ia224': 'imagenet_resnet18_r224_10_161_10_amp',\n",
    "    'ia288': 'imagenet_resnet18_r288_10_141_10_amp',\n",
    "    'iax160': 'imagenet_resnet18_r160_20_1281_20_amp_xla',\n",
    "    'iax224': 'imagenet_resnet18_r224_20_621_20_amp_xla',\n",
    "    'iax288': 'imagenet_resnet18_r288_20_301_20_amp_xla',\n",
    "}\n",
    "gpu_label = ['gpu01', 'gpu02', 'gpu03', 'gpu04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4760a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gl in gpu_label:\n",
    "    for key in files.keys():\n",
    "        files[key].append(\n",
    "            np.load(f'../npy/{gl}/time_{verbose_label[key]}.npy', allow_pickle=True).item()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3899b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in files['c24'][0].items():\n",
    "    print(key, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c98acf",
   "metadata": {},
   "source": [
    "# Create Measurement, Linear Regression Model, and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = {}\n",
    "\n",
    "for key, value in files.items():\n",
    "    measurement[key] = {\n",
    "        'batch_size': np.array(value[0]['batch_size']),\n",
    "        'batch_time': np.zeros_like(value[0]['batch_size'], dtype=float)\n",
    "    }\n",
    "    for item in value:\n",
    "        measurement[key]['batch_time'] += item['avg_train_time']\n",
    "    measurement[key]['batch_time'] /= len(gpu_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = {}\n",
    "\n",
    "for key, value in measurement.items():\n",
    "    reg_model[key] = LinearRegression().fit(\n",
    "        value['batch_size'].reshape(-1, 1),\n",
    "        value['batch_time'],\n",
    "    )\n",
    "    print(key, reg_model[key].intercept_, reg_model[key].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f03bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "\n",
    "for key, value in reg_model.items():\n",
    "    prediction[key] = {\n",
    "        'batch_size': np.arange(1, measurement[key]['batch_size'][-1] + 1),\n",
    "    }\n",
    "    prediction[key]['batch_time'] = value.predict(prediction[key]['batch_size'].reshape(-1, 1))\n",
    "    if 'c' in key: # cifar\n",
    "        prediction[key]['epoch_time'] = (\n",
    "            prediction[key]['batch_time'] * np.ceil(50000 / prediction[key]['batch_size'])\n",
    "        )\n",
    "    elif 'i' in key: # imagenet\n",
    "        prediction[key]['epoch_time'] = (\n",
    "            prediction[key]['batch_time'] * np.ceil(1281167 / prediction[key]['batch_size'])\n",
    "        )\n",
    "    else:\n",
    "        prediction[key]['epoch_time'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdb1ad",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = {\n",
    "    'c': {\n",
    "        'intercept_ls': [],\n",
    "        'coef_ls': [],\n",
    "        'large_batch_size_ls': [600, 570],\n",
    "        'small_batch_size_ls': [],\n",
    "        'total_data_amount': 50000,\n",
    "    },\n",
    "    'cx': {\n",
    "        'intercept_ls': [],\n",
    "        'coef_ls': [],\n",
    "        'large_batch_size_ls': [2560, 1460],\n",
    "        'small_batch_size_ls': [],\n",
    "        'total_data_amount': 50000,\n",
    "    },\n",
    "    'ia': {\n",
    "        'intercept_ls': [],\n",
    "        'coef_ls': [],\n",
    "        'large_batch_size_ls': [340, 160, 140],\n",
    "        'small_batch_size_ls': [],\n",
    "        'total_data_amount': 1281167,\n",
    "    },\n",
    "    'iax': {\n",
    "        'intercept_ls': [],\n",
    "        'coef_ls': [],\n",
    "        'large_batch_size_ls': [1280, 620, 300],\n",
    "        'small_batch_size_ls': [],\n",
    "        'total_data_amount': 1281167,\n",
    "    },\n",
    "}\n",
    "\n",
    "for key, value in reg_model.items():\n",
    "    flag = None\n",
    "    if 'c' == key[0]:\n",
    "        flag = 'cx' if 'x' in key else 'c'\n",
    "    elif 'i' == key[0]:\n",
    "        flag = 'iax' if 'x' in key else 'ia'\n",
    "    else:\n",
    "        raise ValueError(f'flag value \"{flag}\" has problem')\n",
    "    func[f'{flag}']['intercept_ls'].append(reg_model[key].intercept_)\n",
    "    func[f'{flag}']['coef_ls'].append(reg_model[key].coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key1 in func:\n",
    "    print(key1, end=', ')\n",
    "print()\n",
    "for key2 in func['c']:\n",
    "    print(key2, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_time_ratio = 1.05\n",
    "num_total = 4\n",
    "num_small = 0\n",
    "num_large = num_total - num_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b020fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in func.items():\n",
    "    value['large_data_amount'] = round(\n",
    "        extra_time_ratio * value['total_data_amount'] / num_total\n",
    "    ) if num_small else round(value['total_data_amount'] / num_total)\n",
    "    value['small_data_amount'] = round(\n",
    "        (value['total_data_amount'] - value['large_data_amount'] * num_large) / num_small\n",
    "    ) if num_small else 0\n",
    "    for intercept, coef, largeBS in zip(\n",
    "        value['intercept_ls'], value['coef_ls'], value['large_batch_size_ls']\n",
    "    ):\n",
    "        time_origin = (coef + intercept / largeBS) * value['total_data_amount'] / num_total\n",
    "        time_new = time_origin * extra_time_ratio\n",
    "        value['small_batch_size_ls'].append(\n",
    "            round(intercept / (time_new / value['small_data_amount'] - coef)) if num_small\n",
    "            else 0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655d21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50312f",
   "metadata": {},
   "source": [
    "# Plot Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a504ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DPI = 72 # [72, 150, 240, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot files\n",
    "for key, value_ls in files.items():\n",
    "    plt.figure(dpi=DPI)\n",
    "    for gl, value in zip(gpu_label, value_ls):\n",
    "        plt.plot(value['batch_size'], value['avg_train_time'], label=f'file {gl}')\n",
    "    plt.plot(prediction[key]['batch_size'], prediction[key]['batch_time'], '--', label = 'prediction')\n",
    "    plt.title(key)\n",
    "    plt.xlabel('Batch Size')\n",
    "    plt.ylabel('Training Time for a Batch (sec)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=DPI)\n",
    "for key, value in measurement.items():\n",
    "    if 'c' in key:\n",
    "        plt.plot(value['batch_size'], value['batch_time'], label=key + ', measurement')\n",
    "for key, value in prediction.items():\n",
    "    if 'c' in key:\n",
    "        plt.plot(value['batch_size'], value['batch_time'], '--', label=key + ', prediction')\n",
    "plt.title('Training CIFAR-100 on ResNet-18')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Training Time for a Batch (sec)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93190f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=DPI)\n",
    "for key, value in measurement.items():\n",
    "    if 'i' in key:\n",
    "        plt.plot(value['batch_size'], value['batch_time'], label=key + ', measurement')\n",
    "for key, value in prediction.items():\n",
    "    if 'i' in key:\n",
    "        plt.plot(value['batch_size'], value['batch_time'], '--', label=key + ', prediction')\n",
    "plt.title('Training ImageNet on ResNet-18')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Training Time for a Batch (sec)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c048a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=DPI)\n",
    "for key, value in prediction.items():\n",
    "    if 'c' in key:\n",
    "        plt.plot(\n",
    "            value['batch_size'],\n",
    "            value['epoch_time'],\n",
    "            #'--' if 'x' in key else '-',\n",
    "            label=key + ', prediction',\n",
    "        )\n",
    "plt.title('Training CIFAR-100 on ResNet-18')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Training Time for an Epoch (sec)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928be8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=DPI)\n",
    "for key, value in prediction.items():\n",
    "    if 'i' in key:\n",
    "        plt.plot(\n",
    "            value['batch_size'],\n",
    "            value['epoch_time'],\n",
    "            #'--' if 'x' in key else '-',\n",
    "            label=key + ', prediction',\n",
    "        )\n",
    "plt.title('Training ImageNet on ResNet-18')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Training Time for an Epoch (sec)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee09d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
